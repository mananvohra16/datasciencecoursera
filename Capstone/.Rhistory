ylab('Total property and crop damages (log10)') +
ggtitle('Top 10 weather events that causes economic hazards') +
theme_classic()+
options(repr.plot.width = 0.5, repr.plot.height = 0.75)
1
ggplot(data = top_economic[1:10, ], aes(x = reorder(EVTYPE, total), y = total)) +
#need to use reorder to prevent the categorical data from reordering
geom_bar(stat = 'identity') +
coord_flip() +
scale_y_continuous(trans = 'log10') +
xlab('Event type') +
ylab('Total property and crop damages (log10)') +
ggtitle('Top 10 weather events that causes economic hazards') +
theme_classic()+
options(repr.plot.width = 1, repr.plot.height = 0.75)
ggplot(data = top_economic[1:10, ], aes(x = reorder(EVTYPE, total), y = total)) +
#need to use reorder to prevent the categorical data from reordering
geom_bar(stat = 'identity') +
coord_flip() +
scale_y_continuous(trans = 'log10') +
xlab('Event type') +
ylab('Total property and crop damages (log10)') +
ggtitle('Top 10 weather events that causes economic hazards') +
theme_classic()
options
ggplot(data = top_economic[1:10, ], aes(x = reorder(EVTYPE, total), y = total)) +
#need to use reorder to prevent the categorical data from reordering
geom_bar(stat = 'identity') +
coord_flip() +
scale_y_continuous(trans = 'log10') +
xlab('Event type') +
ylab('Total property and crop damages (log10)') +
ggtitle('Top 10 weather events that causes economic hazards') +
theme_classic()+
options(repr.plot.width = 1, repr.plot.height = 0.75)
ggplot(data = top_economic[1:10, ], aes(x = reorder(EVTYPE, total), y = total)) +
#need to use reorder to prevent the categorical data from reordering
geom_bar(stat = 'identity') +
coord_flip() +
scale_y_continuous(trans = 'log10') +
xlab('Event type') +
ylab('Total property and crop damages (log10)') +
ggtitle('Top 10 weather events that causes economic hazards') +
theme_classic()+
options(repr.plot.width = 14, repr.plot.height = 8)
options(repr.plot.width = 14, repr.plot.height = 8)
ggplot(data = top_economic[1:10, ], aes(x = reorder(EVTYPE, total), y = total)) +
#need to use reorder to prevent the categorical data from reordering
geom_bar(stat = 'identity') +
coord_flip() +
scale_y_continuous(trans = 'log10') +
xlab('Event type') +
ylab('Total property and crop damages (log10)') +
ggtitle('Top 10 weather events that causes economic hazards') +
theme_classic()
options(repr.plot.width = 14, repr.plot.height = 8)
Storm_data_q2 <- storm_data[, c(1, 4:7)] %>% rowwise() %>% mutate(prop_dmg = PROPDMG*10**value_conversion(PROPDMGEXP), crop_dmg = CROPDMG*10**value_conversion(CROPDMGEXP))
options(repr.plot.width = 14, repr.plot.height = 8)
ggplot(data = top_health[1:10,], aes(x=reorder(EVTYPE, total), y=total))+
geom_bar(stat = 'identity') +
coord_flip() +
xlab('Event Type') +
ylab('Total health damage') +
ggtitle('Top 10 weather events that causes health hazards')
hist(runif(1000))
mns = NULL
for (i in 1 : 1000) mns = c(mns, mean(runif(40)))
hist(mns)
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(ggplot2)
library(dplyr)
library(datasets)
data(ToothGrowth)
ToothGrowth %>% group_by(supp, dose) %>%
summarise(meanLength = mean(len), medianLength = median(len), sdLength = sd(len))
datasets(mtcars)
dataset(mtcars)
load(mtcars)
mtcars
clear
fit -> lm(mpg ~ factor(cyl) + wt, data = mtcars)
fit <- lm(mpg ~ factor(cyl) + wt, data = mtcars)
fit
summary(fir)$coef
summary(fit)$coef
knitr::opts_chunk$set(echo = TRUE)
data(mtcars)
data -> data(mtcars)
data <- data(mtcars)
head(data)
data <- load(mtcars)
head(data)
data <- data("mtcars")
head(data)
mtcars
head(mtcars)
data("mtcars")
head(mtcars)
data("mtcars")
head(mtcars)
library(ggplot2)
library(ggplot2)
library(dplyr)
mpg_vs_am <- mtcars %>% select(mpg, am)
ggplot(data = mpg_vs_am, aes = (x=am, y=mpg))
ggplot(data = mpg_vs_am, aes = (x=am  , y=mpg))
ggplot(data = mpg_vs_am, aes(x=am  , y=mpg))
ggplot(data = mpg_vs_am, aes(x=am  , y=mpg))+
geom_bar()
ggplot(data = mpg_vs_am, aes(x=am  , y=mpg))+
geom_bar()
ggplot(data = mpg_vs_am, aes(x=am  , y=mpg))+
geom_boxplot()
mpg_vs_am <- mtcars %>% select(mpg, am) %> mutate(am = as.factor(am)
mpg_vs_am <- mtcars %>% select(mpg, am) %> mutate(am = as.factor(am)
mpg_vs_am <- mtcars %>% select(mpg, am) %>% mutate(am = as.factor(am)
mpg_vs_am <- mtcars %>% select(mpg, am) %>% mutate(am = as.factor(am))
mpg_vs_am <- mtcars %>% select(mpg, am) %>% mutate(am = as.factor(am))
ggplot(data = mpg_vs_am, aes(x=am  , y=mpg))+
geom_boxplot()
ggplot(data = mpg_vs_am, aes(x=am  , y=mpg))+
geom_boxplot() + geom_bar()
ggplot(data = mpg_vs_am, aes(x=am  , y=mpg))+
geom_boxplot() + geom_area()
ggplot(data = mpg_vs_am, aes(x=am  , y=mpg))+
geom_boxplot() + geom_abline()
ggplot(data = mpg_vs_am, aes(x=am  , y=mpg))+
geom_boxplot() + geom_point()
ggplot(data = mpg_vs_am, aes(x=am  , y=mpg))+
geom_boxplot() + geom_point()+
xlab("Transmission: 0 - Manual   1 - Automatic")+
ylab("Mpg")
data <- mtcars %>% mutate(
cyl = as.factor(cly),
vs = as.factor(vs),
am = as.factor(am),
gear = as.factor(am),
carb = as.factor(carb))
data <- mtcars %>% mutate(
cyl = as.factor(cyl),
vs = as.factor(vs),
am = as.factor(am),
gear = as.factor(am),
carb = as.factor(carb))
fit_all <- lm(mpg ~. , data = data)
summary(fit_all)$coef[,4]
fit_all <- lm(mpg ~. , data = data)
summary(fit_all)$coef[,4]
whcih.max(summary(fit_all)$coef[,4])
which.max(summary(fit_all)$coef[,4])
data <- data %>% select(-carb)
fit <- lm(mpg ~. , data = data)
summary(fit)$coef[,4]
data <- data %>% select(-carb)
data <- data %>% select(-carb)
fit <- lm(mpg ~. , data = data)
summary(fit)$coef[,4]
which.max(summary(fit)$coef[,4])
data <- data %>% select(-cyl); fit <- lm(mpg ~. , data = data); summary(fit)$coef[,4]
data <- data %>% select(-cyl); fit <- lm(mpg ~. , data = data); summary(fit)$coef[,4];which.max(summary(fit)$coef[,4])
which.max(summary(fit)$coef[,4])
data <- data %>% select(-vs); fit <- lm(mpg ~. , data = data); summary(fit)$coef[,4]; which.max(summary(fit)$coef[,4])
data <- data %>% select(-drat); fit <- lm(mpg ~. , data = data); summary(fit)$coef[,4]; which.max(summary(fit)$coef[,4])
data <- data %>% select(-disp); fit <- lm(mpg ~. , data = data); summary(fit)$coef[,4]; which.max(summary(fit)$coef[,4])
data <- data %>% select(-hp); fit <- lm(mpg ~. , data = data); summary(fit)$coef[,4]; which.max(summary(fit)$coef[,4])
summary(fit)
plot(fit)
par(mfrow = c(2, 2))
plot(fit)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
package.install(AppliedPredictiveModeling)
install.packages(AppliedPredictiveModeling)
install.packages(AppliedPredictiveModeling)
install.packages("AppliedPredictiveModeling")
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
install.packages("Caret")
install.packages("caret")
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
knitr::opts_chunk$set(echo = TRUE)
inTrain <- createDataPartition(y = train$classe, p = 0.7, list = F)
## Loading required libraries
library(caret)
library(randomForest)
#Downloading data
if (!file.exists('train.csv')) {
download.file(url = 'https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv',
destfile = 'train.csv', method = 'curl', quiet = TRUE)
}
if (!file.exists('test.csv')) {
download.file(url = 'https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv',
destfile = 'test.csv', method = 'curl', quiet = TRUE)
}
trainRaw <- read.csv('train.csv')
testRaw <- read.csv('test.csv')
#removing unrelated columns such as column number and time stamp
str(trainRaw)
#removing unrelated columns such as column number and time stamp
str(trainRaw)
train <- trainRaw[, 6:ncol(trainRaw)]
#Train and test data set creation
set.seed(23954)
inTrain <- createDataPartition(y = train$classe, p = 0.7, list = F)
install.packages("Rcpp")
knitr::opts_chunk$set(echo = TRUE)
inTrain <- createDataPartition(y = train$classe, p = 0.7, list = F)
## Loading required libraries
library(caret)
## Loading required libraries
library(caret)
library(randomForest)
#removing unrelated columns such as column number and time stamp
str(trainRaw)
#removing unrelated columns such as column number and time stamp
str(trainRaw)
train <- trainRaw[, 6:ncol(trainRaw)]
#Train and test data set creation
set.seed(23954)
inTrain <- createDataPartition(y = train$classe, p = 0.7, list = F)
training <- train[inTrain, ]
testing<- train[-inTrain, ]
#removing simillar variables
nzv <- nearZeroVar(train, saveMetrics = T)
#removing simillar variables
nzv <- nearZeroVar(train, saveMetrics = T)
keepFeat <- row.names(nzv[nzv$nzv == FALSE, ])
training <- training[, keepFeat]
#removing variables with all NAs
training <- training[, colSums(is.na(training)) == 0]
dim(training)
# 5 fold cross validation
modCtl <- trainControl(method = 'cv', number = 5)
#random forest modeling
set.seed(2384)
modRf <- train(classe ~. , data = training, method = 'rf', trControl = modCtl)
install.packages("e1071")
modRf <- train(classe ~. , data = training, method = 'rf', trControl = modCtl)
#random forest modeling
set.seed(2384)
modRf <- train(classe ~. , data = training, method = 'rf', trControl = modCtl, verbose = TRUE)
# 5 fold cross validation
modCtl <- trainControl(method = 'cv', number = 5,  verboseIter = TRUE)
#random forest modeling
set.seed(2384)
modRf <- train(classe ~. , data = training, method = 'rf', trControl = modCtl, verbose = TRUE)
# 5 fold cross validation
modCtl <- trainControl(method = 'cv', number = 1,  verboseIter = TRUE)
#random forest modeling
set.seed(2384)
modRf <- train(classe ~. , data = training, method = 'rf', trControl = modCtl, verbose = TRUE)
# 5 fold cross validation
modCtl <- trainControl(method = 'cv', number = 1,  verboseIter = TRUE)
#random forest modeling
set.seed(2384)
modRf <- train(classe ~. , data = training, method = 'rf', trControl = modCtl, verbose = TRUE)
# 5 fold cross validation
modCtl <- trainControl(method = 'cv', number = 2,  verboseIter = TRUE)
# 5 fold cross validation
modCtl <- trainControl(method = 'cv', number = 2,  verboseIter = TRUE)
#random forest modeling
set.seed(2384)
modRf <- train(classe ~. , data = training, method = 'rf', trControl = modCtl, verbose = TRUE)
modRf <- train(classe ~. , data = training, method = 'rf', verbose = TRUE)
# 5 fold cross validation
modCtl <- trainControl(method = 'cv', number = 1,  verboseIter = TRUE)
#random forest modeling
set.seed(2384)
modRf <- train(classe ~. , data = training, method = 'rf', trControl = modCtl, verbose = TRUE)
# 5 fold cross validation
modCtl <- trainControl(method = 'cv', number = 2,  verboseIter = TRUE)
#random forest modeling
set.seed(2384)
modRf <- train(classe ~. , data = training, method = 'rf', trControl = modCtl, verbose = TRUE)
# 5 fold cross validation
modCtl <- trainControl(method = 'cv', number = 2,  verboseIter = TRUE, allowParallel = TRUE)
#random forest modeling
set.seed(2384)
modRf <- train(classe ~. , data = training, method = 'rf', trControl = modCtl, verbose = TRUE)
modRf$finalModel
predRf <- predict(modRf, newdata = testing)
confusionMatrix(predRf, testing$classe)$table
predRf <- predict(modRf, newdata = testing)
confusionMatrix(predRf, testing$classe)$table
testing<- train[-inTrain, ]
confusionMatrix(predRf, testing$classe)$table
#removing simillar variables
nzv <- nearZeroVar(testing, saveMetrics = T)
keepFeat <- row.names(nzv[nzv$nzv == FALSE, ])
testing <- testing[, keepFeat]
#removing variables with all NAs
testing <- testing[, colSums(is.na(testing)) == 0]
dim(testing)
predRf <- predict(modRf, newdata = testing)
confusionMatrix(predRf, testing$classe)$table
confusionMatrix(predRf, testing$classe)$table[1]
# 5 fold cross validation
modCtl <- trainControl(method = 'cv', number = 5,  verboseIter = TRUE, allowParallel = TRUE)
#random forest modeling
set.seed(2384)
modRf <- train(classe ~. , data = training, method = 'rf', trControl = modCtl, verbose = TRUE)
modRf$finalModel
predRf <- predict(modRf, newdata = testing)
confusionMatrix(predRf, testing$classe)$table
confusionMatrix(predRf, testing$classe)$overall[1]
modGbm <- train(classe ~., data = training, method = 'gbm', trControl = modCtl, verbose = F)
confusionMatrix(predRf, testing$classe)$table
confusionMatrix(predRf, testing$classe)
)
predRf <- format(round(predict(modRf, newdata = testing)))
predRf <- predict(modRf, newdata = testing)
predRf
testing$classe
testing$classe
predRf
testing$classe
predRf <- as.character(predict(modRf, newdata = testing))
predRf <- as.character(predict(modRf, newdata = testing))
predRf
confusionMatrix(predRf, testing$classe)$table
predRf
testing$classe
class(testing$classe)
class(predRf)
predRf <- as.character(predict(modRf, newdata = testing))
confusionMatrix(predRf, testing$classe)$table
confusionMatrix(predRf, testing$classe)$overall[1]
table(predRf)
table(testing$classe)
table(factor(predRf, levels=min(test):max(test)),
factor(testing$classe, levels=min(test):max(test)))
table(factor(predRf, levels=min(testing$classe):max(testing$classe)),
factor(testing$classe, levels=min(testing$classe):max(testing$classe)))
predRf <- predict(modRf, newdata = testing)
class(predRf)
confusionMatrix(predRf, as.factor(testing$classe))$table
confusionMatrix(predRf, as.factor(testing$classe))$overall[1]
predRf <- predict(modRf, newdata = testing)
confusionMatrix(predRf, as.factor(testing$classe))$table
confusionMatrix(predRf, as.factor(testing$classe))$overall[1]
modGbm <- train(classe ~., data = training, method = 'gbm', trControl = modCtl, verbose = F)
modGbm$finalModel
predGbm <- predict(modGbm, newdata = testing)
confusionMatrix(predGbm, testing$classe)$table
predGbm <- predict(modGbm, newdata = testing)
confusionMatrix(predGbm, as.factor(testing$classe))$table
confusionMatrix(predGbm, as.factor(testing$classe))$overall[1]
predRfTest <- predict(modRf, newdata = testRaw)
predRfTest
predRfTest <- predict(modRf, newdata = testRaw)
predRfTest
predGbmTest <- predict(modGbm, newdata = testRaw)
table(predRfTest, predGbmTest)
knitr::opts_chunk$set(echo = TRUE)
#Test data error check
predRf <- predict(modRf, newdata = testing)
install.packages('leaflet')
knitr::opts_chunk$set(echo = TRUE)
library(leaflet)
library(htmltools)
m <- leaflet() %>%
addTiles() %>%  # Add default OpenStreetMap map tiles
addMarkers(lng=77.1025, lat=-28.7041, popup="The birthplace of R")
m  # Print the map
m <- leaflet() %>%
addTiles() %>%  # Add default OpenStreetMap map tiles
addMarkers(lng=77.1025, lat=-20.7041, popup="The birthplace of R")
m  # Print the map
m <- leaflet() %>%
addTiles() %>%  # Add default OpenStreetMap map tiles
addMarkers(lng=77.1025, lat=28.7041, popup="The birthplace of R")
m  # Print the map
dataset(iris)
datasets::iris
plotly(iris)
library(plotly)
plotly(iris)
plot_ly(iris)
plot_ly(data = iris)
plot_ly(economics, x = ~date, y = ~pop)
plot_ly(data = iris, x = ~Sepal.Length, y = ~Petal.Length)
plot_ly(economics, x = ~date, y = ~pop)
plot_ly(data = iris, x = ~Sepal.Length, y = ~Petal.Length)
plot_ly(data = economics, x = ~date, y = ~pop)
economics
iris
install.packages("webshot")
library(plotly)
plot_ly(data = iris, x = ~Sepal.Length, y = ~Petal.Length)
library(plotly)
trace_0 <- rnorm(100, mean = 5)
trace_1 <- rnorm(100, mean = 0)
trace_2 <- rnorm(100, mean = -5)
x <- c(1:100)
data <- data.frame(x, trace_0, trace_1, trace_2)
fig <- plot_ly(data, x = ~x, y = ~trace_0, name = 'trace 0', type = 'scatter', mode = 'lines')
fig <- fig %>% add_trace(y = ~trace_1, name = 'trace 1', mode = 'lines+markers')
fig <- fig %>% add_trace(y = ~trace_2, name = 'trace 2', mode = 'markers')
fig
shiny::runApp('project_9_3')
fithful
faithful
runApp('project_9_3')
iris
head(iiris)
head(iris)
runApp('project_9_3')
unique(iris$Species)
runApp('project_9_3')
runApp('project_9_3')
runApp('project_9_3')
runApp('project_9_3')
data <- iris[iris$Species == "setosa"]
data <- iris[Species == "setosa"]
data <- iris["Species" == "setosa"]
data
data <- iris[iris$Species == "setosa",]
data
runApp('project_9_3')
runApp('project_9_3')
runApp('project_9_3')
runApp('project_9_3')
runApp('project_9_3')
runApp('project_9_3')
iris$Species
iris$Species[]1
iris$Species[1}
iris$Species[1]
runApp('project_9_3')
runApp('project_9_3')
unique(iris$Species)
runApp('project_9_3')
runApp('project_9_3')
runApp('project_9_3')
runApp('project_9_3')
runApp()
runApp('project_9_3')
runApp('project_9_3')
getwd()
runApp('GitHub/datasciencecoursera/Course 9')
summary(iris)
library(ggplot)
ggplot(iris, aes(x=Sepal.Width, y=Sepal.Length)) +
geom_point() +
labs(title = "Sepal width vs Sepal length plot")
library(ggplot2)
ggplot(iris, aes(x=Sepal.Width, y=Sepal.Length)) +
geom_point() +
labs(title = "Sepal width vs Sepal length plot")
library(ggplot2)
fig <- ggplot(iris, aes(x=Sepal.Width, y=Sepal.Length)) +
geom_point() +
labs(title = "Sepal width vs Sepal length plot")
htmlwidgets::saveWidget(as.widget(fig), file = "demo.html")
knitr::opts_chunk$set(echo = TRUE)
library(plyr)
library(magrittr)
library(stringr)
library(stringi)
library(tm)
install.packages("tm")
install.packages("RWeka")
install.packages("SnowballC")
library(plyr)
library(magrittr)
library(stringr)
library(stringi)
library(tm)
library(RWeka)
install.packages("RWeka")
library(RWeka)
Blogs <- suppressWarnings(readLines("/data/en_US.blogs.txt", skipNul = TRUE, encoding = "UTF-8"))
Blogs <- suppressWarnings(readLines("./data/en_US.blogs.txt", skipNul = TRUE, encoding = "UTF-8"))
setwd("~/GitHub/datasciencecoursera/Capstone")
Blogs <- suppressWarnings(readLines("./data/en_US.blogs.txt", skipNul = TRUE, encoding = "UTF-8"))
Blogs <- suppressWarnings(readLines("./data/en_US.blogs.txt", skipNul = TRUE, encoding = "UTF-8"))
Blogs <- suppressWarnings(readLines("./data/en_US.blogs.txt", skipNul = TRUE, encoding = "UTF-8"))
Blogs <- suppressWarnings(readLines("./data/en_US/en_US.blogs.txt", skipNul = TRUE, encoding = "UTF-8"))
Blogs <- suppressWarnings(readLines("./data/en_US/en_US.blogs.txt", skipNul = TRUE, encoding = "UTF-8"))
Twitter <- suppressWarnings(readLines("data/en_US/en_US.twitter.txt", skipNul = TRUE, encoding = "UTF-8"))
News <- suppressWarnings(readLines("data/en_US/en_US.news.txt", skipNul = TRUE, encoding = "UTF-8"))
BlogS
Blogs
clear
summary(Blogs)
Blogs[5]
head(Blogs)
head(Twitter,5)
head(News,5)
stri_stats_general(News)
set.seed(9999)
Sub_Twitter <- sample(Twitter, size = 5000, replace = TRUE)
Sub_Blogs <- sample(Blogs, size = 5000, replace = TRUE)
Sub_News <- sample(News, size = 5000, replace = TRUE)
#Union the sample datasets
Dataset <- c(Sub_Twitter, Sub_Blogs, Sub_News)
library(tm)
Corpus <- Corpus(VectorSource(Dataset))
library(tm)
Corpus <- Corpus(VectorSource(Dataset))
data_clean <- removePunctuation(Dataset)
data_clean <- tolower(data_clean)
data_clean <- removeNumbers(data_clean)
data_clean <- stripWhitespace(data_clean)
data_clean <- stemDocument(data_clean)
saveRDS(data_clean, file = "data_clean.RData")
